{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a963966-a828-4bc9-9c06-27a1a29c6cef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.0)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.8.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.51.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (67.1.0)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.28.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.12\n",
      "    Uninstalling protobuf-4.21.12:\n",
      "      Successfully uninstalled protobuf-4.21.12\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.1.21 gast-0.4.0 google-auth-2.16.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.3 keras-2.11.0 libclang-15.0.6.1 markdown-3.4.1 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.2.0 werkzeug-2.2.3 wrapt-1.15.0\n",
      "Collecting git+https://github.com/carlosluis/stable-baselines3@fix_tests\n",
      "  Cloning https://github.com/carlosluis/stable-baselines3 (to revision fix_tests) to /tmp/pip-req-build-dh3huhkz\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/carlosluis/stable-baselines3 /tmp/pip-req-build-dh3huhkz\n",
      "  Running command git checkout -b fix_tests --track origin/fix_tests\n",
      "  Switched to a new branch 'fix_tests'\n",
      "  Branch 'fix_tests' set up to track remote branch 'fix_tests' from 'origin'.\n",
      "  Resolved https://github.com/carlosluis/stable-baselines3 to commit c5a5d732ee8743c512bf14cb338c4fc2c9b80ec3\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gym==0.26.2\n",
      "  Using cached gym-0.26.2.tar.gz (721 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from stable-baselines3==2.0.0a0) (1.23.5)\n",
      "Collecting torch>=1.11\n",
      "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m766.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:06\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from stable-baselines3==2.0.0a0) (2.2.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from stable-baselines3==2.0.0a0) (1.5.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from stable-baselines3==2.0.0a0) (3.6.3)\n",
      "Collecting importlib-metadata~=4.13\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata~=4.13->stable-baselines3==2.0.0a0) (3.13.0)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m816.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (4.4.0)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable-baselines3==2.0.0a0) (67.1.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable-baselines3==2.0.0a0) (0.38.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a0) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a0) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a0) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a0) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a0) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a0) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a0) (1.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->stable-baselines3==2.0.0a0) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.0.0a0) (1.16.0)\n",
      "Building wheels for collected packages: stable-baselines3, gym\n",
      "  Building wheel for stable-baselines3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for stable-baselines3: filename=stable_baselines3-2.0.0a0-py3-none-any.whl size=174426 sha256=eeae7a64694e1eec67ac41e15e5a5deb7094e2502420f3e49b8ac44a4573d4a3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vdx79fcf/wheels/cc/40/56/e6db2f8ff9427b0849f4c6ddbe003a53a5f61f31aae2f9ccb7\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827635 sha256=21ffeb490cf2f60c209cc1f69abc4bdb5668718a585942c91f97cb5bc29a9fcd\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
      "Successfully built stable-baselines3 gym\n",
      "Installing collected packages: gym-notices, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, importlib-metadata, gym, nvidia-cudnn-cu11, torch, stable-baselines3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.0.0\n",
      "    Uninstalling importlib-metadata-6.0.0:\n",
      "      Successfully uninstalled importlib-metadata-6.0.0\n",
      "Successfully installed gym-0.26.2 gym-notices-0.0.8 importlib-metadata-4.13.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 stable-baselines3-2.0.0a0 torch-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install git+https://github.com/carlosluis/stable-baselines3@fix_tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "81c172ae-f64b-4fb8-95d1-85a6a80433df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, MultiDiscrete\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "10fd7f86-2f83-4519-b273-979e793800b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_name = 'tria-3d-rl-model-'\n",
    "\n",
    "t_ini= 70.0; h_ini= 40.0; a_ini= 10.0 \n",
    "\n",
    "t_min =-40.0; t_max=110; h_min=0.0; h_max=100.0; a_min=0.0; a_max=5000.0\n",
    "\n",
    "act_state = 2\n",
    "\n",
    "stat_rand_min = -1.0; stat_rand_max = 1.0\n",
    "\n",
    "equilibrium_cycles= 60\n",
    "\n",
    "r1 = -0.25; r2 = -0.5; r3 = 2; nr3 = -2\n",
    "\n",
    "const_weight_vec  = [1, 1, 1, 1]\n",
    "\n",
    "d3 = {\n",
    "     0 : [65.0, 80.0, 50.0, 85.0, 40.0, 90.0], \n",
    "     1 : [30.0, 50.0, 20.0, 60.0, 10.0, 70.0], \n",
    "     2 : [0.0, 19.0, 200.0, 599.0, 600.0, 2000.0]\n",
    "    }\n",
    "\n",
    "d1 = {0: [65.0, 80.0], 1: [30.0, 50.0], 2: [0.0, 20.0]}\n",
    "\n",
    "ppo_model_timesteps= 20000; neural_model_timesteps=2000; a2c_model_timesteps=20000\n",
    "\n",
    "ppo_model = env_name + 'ppo'; neural_model = env_name + 'ppo-neural'; a2c_model = env_name + 'a2c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c50b8021-660f-4af2-8c2b-0ab2c0fa9149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TriaEnv(Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.action_space = MultiDiscrete(np.array([act_state,act_state,act_state,act_state,act_state]))\n",
    "        \n",
    "        self.observation_space = Box(low=np.array([t_min, h_min, a_min]), high=np.array([t_max, h_max, a_max]), dtype=np.float32)\n",
    "        \n",
    "        self.state = [TINI + random.uniform(stat_rand_min, stat_rand_max), HINI + random.uniform(stat_rand_min, stat_rand_max), AINI + random.uniform(stat_rand_min, stat_rand_max)]\n",
    "        \n",
    "        #print('^^^', self.state, self.action_space)\n",
    "        \n",
    "        self.equilibrium_cycles_len = equilibrium_cycles\n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        ap_scaled = [1 if e == 1 else -1 for e in action]  # 0 (off) => -1 and 1 (on) => 1\n",
    "        \n",
    "        actionPrime = [a * b for a, b in zip(ap_scaled, const_weight_vec)] \n",
    "        \n",
    "        actionAlgo = [actionPrime[a] - actionPrime[len(actionPrime) -a -1] for a in range(len(actionPrime) // 2)]\n",
    "        \n",
    "        actionAlgo.append(actionPrime[len(actionPrime) // 2])                                                              \n",
    "        \n",
    "        #print('***',actionAlgo, self.state)\n",
    "        \n",
    "        self.state = [a + b for a, b in zip(actionAlgo, self.state)]\n",
    "        \n",
    "        #print('&&&', actionAlgo, self.state)\n",
    "        \n",
    "        #reduce tria simulation length by 1 second\n",
    "        self.equilibrium_cycles_len -= 1\n",
    "        \n",
    "        reward = [r3 if e >= d3[i][0] and e<= d3[i][1] else r2 if e >= d3[i][2] and e<= d3[i][3] else r1 if e >= d3[i][4] and e <= d3[i][5] else nr3 for i, e in enumerate(self.state)]\n",
    "        #reward = [r3 if e >= d1[i][0] and e <= d1[i][1] else nr3  for i, e in enumerate(self.state)]\n",
    "\n",
    "        reward = sum(reward)\n",
    "        #print('$$$', reward)\n",
    "            \n",
    "        if self.equilibrium_cycles_len <= 0:\n",
    "            terminated = True\n",
    "        else:\n",
    "            terminated = False\n",
    "            \n",
    "        info = {}\n",
    "        #print('reward:{} state:{}'.format(reward, self.state))\n",
    "        return self.state, reward, terminated, False, info\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        \n",
    "        self.state =[t_ini + random.uniform(stat_rand_min, stat_rand_max),h_ini + random.uniform(stat_rand_min, stat_rand_max),a_ini + random.uniform(stat_rand_min, stat_rand_max)]\n",
    "        #print('@@@', self.state)\n",
    "        self.equilibrium_cycles_len = equilibrium_cycles\n",
    "        \n",
    "        return self.state, {}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ba3c7274-5a3f-4b51-bb68-4b4eb53ab266",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Sample observation space: [  43.429573   98.13569  4064.025   ]\n",
      "2. Sample action space     : [0 1 1 1 0]\n",
      "3. Sample state            : [69.9576193306034, 40.344744239639574, 9.82955435523851]\n"
     ]
    }
   ],
   "source": [
    "env= TriaEnv()\n",
    "\n",
    "print(\"1. Sample observation space: {}\".format(env.observation_space.sample()))\n",
    "print(\"2. Sample action space     : {}\".format(env.action_space.sample()))\n",
    "print(\"3. Sample state            : {}\".format(env.state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "25dab386-ce05-4828-a349-724a40fb963d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Score: 250.0\n",
      "Episode: 2 Score: 169.75\n",
      "Episode: 3 Score: 286.5\n",
      "Episode: 4 Score: 187.5\n",
      "Episode: 5 Score: 166.75\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    #print(state)\n",
    "    terminated = False\n",
    "    score = 0 #[0,0,0] \n",
    "    \n",
    "    while not terminated:\n",
    "        #env.render()\n",
    "        action = env.action_space.sample()\n",
    "        #print(action, terminated , reward)\n",
    "        #print(env.step(action))\n",
    "        next_state, reward, terminated, truncated, info = env.step(action) \n",
    "        score += reward #[a + b for a, b in zip(reward, score)]\n",
    "    print('Episode: {} Score: {}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d6de899a-0760-4944-aad9-2264d84f6b11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training/logs'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path = os.path.join('training','logs')\n",
    "log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b82295d4-05b8-45d6-b8b2-f662dac0e943",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "61be825c-c196-4804-8892-07eac009d578",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to training/logs/PPO_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 137  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 14   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 116          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080285985 |\n",
      "|    clip_fraction        | 0.0708       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.46        |\n",
      "|    explained_variance   | 0.000852     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00896     |\n",
      "|    value_loss           | 2.56e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008792361 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.00529     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    value_loss           | 3.24e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008255887 |\n",
      "|    clip_fraction        | 0.0603      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 3.62e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    value_loss           | 3.02e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006956985 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.0026      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.5e+03     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    value_loss           | 3.1e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 121          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087680295 |\n",
      "|    clip_fraction        | 0.0719       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.44        |\n",
      "|    explained_variance   | 0.000106     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.29e+03     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00947     |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 142        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00842678 |\n",
      "|    clip_fraction        | 0.0618     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.44      |\n",
      "|    explained_variance   | 0.000226   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.66e+03   |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00422   |\n",
      "|    value_loss           | 3.29e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008082032 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.000111    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.6e+03     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    value_loss           | 2.87e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009017022 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.42       |\n",
      "|    explained_variance   | 0.00323     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.44e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    value_loss           | 3.04e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 97         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 209        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01017009 |\n",
      "|    clip_fraction        | 0.0978     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.41      |\n",
      "|    explained_variance   | 0.00355    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.51e+03   |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.00774   |\n",
      "|    value_loss           | 3.01e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7efbf1f7a3b0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=ppo_model_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6c43dc77-e0bf-4e8b-9c89-3b373f9d920c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tria_model_path = os.path.join('training','save', ppo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6bd206a9-4af1-4c35-9339-925995098145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(tria_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6707d749-2fd9-4175-8932-a4bcfd968b12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1068d176-331f-457d-a92a-4632830a8c7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PPO.load(tria_model_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d65c567d-de8b-485b-a5f8-49ef3c65b1db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360.0, 0.0)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=20, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "89d4bb19-d542-48b7-ae87-11f6201024c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0c7d4335-5cce-4c50-b872-e3b08c338895",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episone:1 Score:[317.75]\n",
      "Episone:2 Score:[222.5]\n",
      "Episone:3 Score:[322.5]\n",
      "Episone:4 Score:[357.5]\n",
      "Episone:5 Score:[261.]\n",
      "Episone:6 Score:[357.5]\n",
      "Episone:7 Score:[332.5]\n",
      "Episone:8 Score:[355.]\n",
      "Episone:9 Score:[352.5]\n",
      "Episone:10 Score:[252.5]\n"
     ]
    }
   ],
   "source": [
    "episodes=10\n",
    "for episode in range(1, episodes+1):\n",
    "    observation = env.reset()\n",
    "    terminated = False\n",
    "    score = 0\n",
    "    while not terminated:\n",
    "        env.render()\n",
    "        action, _ = model.predict(observation)\n",
    "        observation, reward, terminated , info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episone:{} Score:{}'.format( episode, score))\n",
    "env.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0dd5b-ca0f-417c-a0fd-b59a5de347d6",
   "metadata": {},
   "source": [
    "# custom neural network injected in PPO model based on tria 3D environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1b08a4c4-1774-4cab-b40c-df5e012cd8d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_arch = dict(pi=[128,128,128,128], vf=[128,128,128,128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a4a397f4-fe4c-4d45-8d96-235892eff1e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path, policy_kwargs={'net_arch':net_arch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "921b3322-3ebc-4b86-be0a-3a49c14dc4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to training/logs/PPO_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 109  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 18   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7efbf1f7a980>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=neural_model_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "42133ad3-55e6-4360-8fe6-df56b8aad79c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tria_model_path_neural = os.path.join('training','save',neural_model)\n",
    "model.save(tria_model_path_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2c0e0238-dd44-4c72-b471-780d2fe06acd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d57f9be4-c706-47c3-89c7-3e38c605ac37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PPO.load(tria_model_path_neural, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7fcb33ae-f76e-4439-8d6a-b473e59a25ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-108.0, 11.24221953174728)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=20, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f8f7abf8-abca-4ce2-b0be-d7b3f301c5db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c46152b-da4c-4cc6-8773-eb271d228afb",
   "metadata": {},
   "source": [
    "# create A2C network based learing with Tria 3D environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2bb08669-342f-4246-8e22-7fe7cf9d6e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7db81c59-f65e-4d8a-b1a5-ea4a5a21db77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = A2C(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "02068e5c-6b50-4dbe-b324-0634e8d03a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to training/logs/A2C_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | 0.0298   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 14.3     |\n",
      "|    value_loss         | 89.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 72       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.91    |\n",
      "|    explained_variance | -0.0397  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.26     |\n",
      "|    value_loss         | 1.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 75       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.33    |\n",
      "|    explained_variance | 0.0306   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 14.3     |\n",
      "|    value_loss         | 34.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.679   |\n",
      "|    explained_variance | 1.45e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 4.86     |\n",
      "|    value_loss         | 34.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 75       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.476   |\n",
      "|    explained_variance | 0.000151 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 9.57     |\n",
      "|    value_loss         | 32.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 75       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.438   |\n",
      "|    explained_variance | 0.0382   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 1.42     |\n",
      "|    value_loss         | 27.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.311   |\n",
      "|    explained_variance | 1.6e-05  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.318    |\n",
      "|    value_loss         | 29.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.344   |\n",
      "|    explained_variance | 0.00366  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.389    |\n",
      "|    value_loss         | 28.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.367   |\n",
      "|    explained_variance | 0.556    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.132    |\n",
      "|    value_loss         | 4.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 75       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.361   |\n",
      "|    explained_variance | 3.97e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.449    |\n",
      "|    value_loss         | 25.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 75        |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.131    |\n",
      "|    explained_variance | 0.498     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -0.000614 |\n",
      "|    value_loss         | 2.37      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.164   |\n",
      "|    explained_variance | 0.954    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.441    |\n",
      "|    value_loss         | 1.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0903  |\n",
      "|    explained_variance | 1.68e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.0595   |\n",
      "|    value_loss         | 22.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0722  |\n",
      "|    explained_variance | 0.00493  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.0449   |\n",
      "|    value_loss         | 21.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0575  |\n",
      "|    explained_variance | 0.906    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.00896  |\n",
      "|    value_loss         | 1.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0415  |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.0229   |\n",
      "|    value_loss         | 19.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0288  |\n",
      "|    explained_variance | 0.000218 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.0145   |\n",
      "|    value_loss         | 18.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0323  |\n",
      "|    explained_variance | 0.853    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.0143  |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0464  |\n",
      "|    explained_variance | 6.13e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.0257   |\n",
      "|    value_loss         | 16.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0617  |\n",
      "|    explained_variance | 0.967    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.0131   |\n",
      "|    value_loss         | 1.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.296   |\n",
      "|    explained_variance | -23.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.919   |\n",
      "|    value_loss         | 131      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.224   |\n",
      "|    explained_variance | 0.407    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.0244  |\n",
      "|    value_loss         | 5.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.251   |\n",
      "|    explained_variance | -3.04    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.61    |\n",
      "|    value_loss         | 101      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.178   |\n",
      "|    explained_variance | 0.448    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.179    |\n",
      "|    value_loss         | 20.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.23    |\n",
      "|    explained_variance | 0.36     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 2.15     |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.394   |\n",
      "|    explained_variance | -14.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -5.11    |\n",
      "|    value_loss         | 151      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.409   |\n",
      "|    explained_variance | -0.0504  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.829   |\n",
      "|    value_loss         | 1.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.375   |\n",
      "|    explained_variance | 0.987    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.0564  |\n",
      "|    value_loss         | 0.844    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.14    |\n",
      "|    explained_variance | 0.447    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 3.39     |\n",
      "|    value_loss         | 9.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.3     |\n",
      "|    explained_variance | 0.322    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 0.22     |\n",
      "|    value_loss         | 7.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.102   |\n",
      "|    explained_variance | 0.00119  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.0612   |\n",
      "|    value_loss         | 10.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0797  |\n",
      "|    explained_variance | 0.00126  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 0.0427   |\n",
      "|    value_loss         | 9.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0785  |\n",
      "|    explained_variance | 0.0747   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.0361   |\n",
      "|    value_loss         | 7.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.145   |\n",
      "|    explained_variance | 0.000677 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.0842   |\n",
      "|    value_loss         | 7.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0848  |\n",
      "|    explained_variance | 0.309    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 1.4      |\n",
      "|    value_loss         | 1.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0785  |\n",
      "|    explained_variance | 0.897    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.0249   |\n",
      "|    value_loss         | 2.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0408  |\n",
      "|    explained_variance | 0.00483  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 1.55     |\n",
      "|    value_loss         | 6.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0329  |\n",
      "|    explained_variance | 0.518    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.00672  |\n",
      "|    value_loss         | 2.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.012   |\n",
      "|    explained_variance | 0.957    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.000356 |\n",
      "|    value_loss         | 0.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00707 |\n",
      "|    explained_variance | 0.000224 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.00173  |\n",
      "|    value_loss         | 4.8      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7efbf1f783d0>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=a2c_model_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f46f6b43-8f4c-430f-9229-4c412a72fc45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tria_model_path_a2c = os.path.join('training','save',a2c_model)\n",
    "model.save(tria_model_path_a2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cc4f6dd7-37bb-4793-b31c-1c4da4359d12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "04c5b9d8-807d-4611-8288-8408a85ca30a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = A2C.load(tria_model_path_a2c, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c9e7cda8-4990-4602-82ee-ab45d53df9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154.2, 1.9899748742132397)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=20, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ff95a3e7-2b05-4575-aaa7-7e7279461af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367724dc-d979-4974-9ce1-a9ba8671888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir './training/logs/' --bind_all  # training_log_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
